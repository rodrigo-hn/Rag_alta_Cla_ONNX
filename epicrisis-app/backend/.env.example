# ============================================
# CONFIGURACIÓN DE BASE DE DATOS ORACLE
# ============================================

# Credenciales de Oracle
DB_USER=your_oracle_user
DB_PASSWORD=your_oracle_password
DB_CONNECT_STRING=localhost:1521/ORCLPDB1

# Pool de conexiones
DB_POOL_MIN=2
DB_POOL_MAX=10
DB_POOL_INCREMENT=1

# ============================================
# CONFIGURACIÓN DEL SERVIDOR
# ============================================

# Puerto del servidor backend
PORT=3000

# Entorno (development, production, test)
NODE_ENV=development

# CORS - Orígenes permitidos (separados por coma)
CORS_ORIGINS=http://localhost:4200,http://localhost:3000

# ============================================
# CONFIGURACIÓN DE MODELOS LLM
# ============================================

# Tipo de modelo: local, openai, anthropic
MODEL_TYPE=local

# --- MODELOS LOCALES ---
# Ruta al modelo LLM local (archivo GGUF completo)
# Opciones recomendadas:
#   TinyLlama (637MB - desarrollo/pruebas):
#     ../models/llm/tinyllama-1.1b-chat-q4/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf
#
#   Llama 3.2 3B (1.9GB - balance ideal):
#     ../models/llm/llama-3.2-3b-instruct-q4/Llama-3.2-3B-Instruct-Q4_K_M.gguf
#
#   Mistral 7B (4.1GB - producción):
#     ../models/llm/mistral-7b-instruct-q4/mistral-7b-instruct-v0.2.Q4_K_M.gguf

LLM_MODEL_PATH=../models/llm/tinyllama-1.1b-chat-q4/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf

# Ruta a modelo de embeddings (directorio completo)
EMBEDDING_MODEL_PATH=../models/embeddings/multilingual-e5-small

# Configuración de inferencia del LLM
MAX_TOKENS=2048
TEMPERATURE=0.3
TOP_P=0.9
TOP_K=40

# Número de threads para CPU (ajustar según cores disponibles)
N_THREADS=4

# --- API OPENAI (Alternativa) ---
# Descomenta si usas MODEL_TYPE=openai
# OPENAI_API_KEY=sk-...
# OPENAI_MODEL=gpt-4-turbo-preview
# OPENAI_MAX_TOKENS=2048

# --- API ANTHROPIC (Alternativa) ---
# Descomenta si usas MODEL_TYPE=anthropic
# ANTHROPIC_API_KEY=sk-ant-...
# ANTHROPIC_MODEL=claude-3-opus-20240229

# ============================================
# VALIDACIÓN CLÍNICA
# ============================================

# Habilitar validación automática
ENABLE_VALIDATION=true

# Diccionario de sinónimos médicos chilenos
SYNONYMS_PATH=./config/synonyms.json

# ============================================
# LOGGING
# ============================================

# Nivel de log: error, warn, info, debug
LOG_LEVEL=info

# Directorio de logs
LOG_DIR=./logs

# Log de queries SQL (solo desarrollo)
LOG_SQL_QUERIES=false

# ============================================
# CACHÉ
# ============================================

# Habilitar caché de resultados
ENABLE_CACHE=true

# TTL del caché en segundos
CACHE_TTL=3600

# ============================================
# EXPORTACIÓN
# ============================================

# Directorio temporal para PDFs/Word
EXPORT_TMP_DIR=./tmp/exports

# Formato de fecha
DATE_FORMAT=DD/MM/YYYY

# Nombre del hospital (para documentos)
HOSPITAL_NAME=Hospital Regional

# ============================================
# NOTAS IMPORTANTES
# ============================================

# 1. DESCARGAR MODELOS PRIMERO:
#    python download_models.py --all
#
# 2. MODELOS RECOMENDADOS:
#    - Desarrollo: TinyLlama (rápido, 637MB)
#    - Producción: Mistral 7B (mejor calidad, 4.1GB)
#
# 3. PRIVACIDAD:
#    MODEL_TYPE=local garantiza que los datos NO salen del servidor
#
# 4. RENDIMIENTO:
#    Ajusta N_THREADS según tus CPU cores para mejor velocidad
